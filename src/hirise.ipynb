{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiRISENet-Tiny\n",
    "\n",
    "A tiny neural network classifier for Mars HiRISE images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mars HiRISE (High Resolution Imaging Science Experiment) [[1]](#1) is a camera on board the Mars Reconnaissance\n",
    "Orbiter which has been orbiting and studying Mars since 2006. A product of this payload's years of service has been the\n",
    "curation of the Mars orbital image (HiRISE) labeled data set [[2]](#2) by NASA. This dataset provides a curated set of\n",
    "labelled images of the Martian terrain from an orbital perspective. **Figure 1** shows one of the first images taken\n",
    "with the HiRISE camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- Public Domain, https://commons.wikimedia.org/w/index.php?curid=656514 >\n",
    "--->\n",
    "![First HiRISE Image](../assets/images/mro_first_image.jpg \"Figure 1. The first orbital image captured by HiRISE\")\n",
    "\n",
    "**Figure 1. Crop of one of the first images of Mars from the HiRISE camera.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2018, Wagstaff et. al. [[3]](#3) set out to train a deep learning model to enable scientists & researchers to conduct\n",
    "advanced queries of the HiRISE data in NASA's planetary imagery database. With the first edition of the dataset, the\n",
    "authors fine-tuned the AlexNet convolutional neural network on the data. This initial dataset contained 3,820 \n",
    "greyscale images and consisted of the labels crater, dark dune, bright dune, dark slope streak, other and edge. With\n",
    "this dataset, the model achieved 99.1%, 88.1%, and 90.6% accuracy across their training, validation, and test sets\n",
    "respectively.\n",
    "\n",
    "Following this effort, Wagstaff et. al. published a follow up paper [[4]](#4) which expanded the initial dataset to\n",
    "a version 3.2. This expanded dataset consists of a total of 64,947 landmark images. These images have been preprocessed\n",
    "and cropped to a 227x227 size similar to the first edition. In v3.2, a subset of these images, 9,022, were augmented \n",
    "using a variety of image augmentation techniques applied individually to the subset of images. This artificially\n",
    "expanded the available data. The authors also introduced the classes impact ejecta, spiders, and swiss cheese while\n",
    "removing edge.\n",
    "\n",
    "![HiRISE v3.2 Class Imagse](../assets/images/hirise_v3_classes.png)\n",
    "\n",
    "The authors also fine-tuned the AlexNet model on the new dataset. For this iteration, the authors analyzed the model's\n",
    "confidence and utilized calibration techniques to make the model more reliable. With this approach and improved dataset,\n",
    "the authors managed to improve the model's classification accuracy to\n",
    "{\"train\": 99.6%, \"val\": 88.6%, \"test\": 92.8%}.\n",
    "\n",
    "![Dataset Class Distribution](../assets/images/hirise_dataset_class_distribution.png)\n",
    "\n",
    "An important thing to note is that the class distribution is pretty unbalanced. Images of \"Other\" significantly\n",
    "dominate the dataset while \"Impact Ejecta\" constitutes a small portion of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Project\n",
    "\n",
    "In this project I challenged myself to develop a pipeline for training and\n",
    "deployment of a neural network to run on the NVIDIA Jetson Nano 2GB. This neural\n",
    "network shall be able to classify the greyscale HiRISE images.\n",
    "\n",
    "My goal is to train a modern convolutional neural network that is more resource\n",
    "efficient than AlexNet and, hopefully, as good as the author's trained AlexNet.\n",
    "\n",
    "As a flight software engineer, I am focused on creating a trusted model that is\n",
    "also resource efficient. As part of this project I also want to analyze and\n",
    "evaluate the resource utilization and performance of the model.\n",
    "\n",
    "Previous work by Dunkel et. al. [[5]](#5) provides some clues as to metrics\n",
    "machine learning practitioners should be cognisant of for a space-based\n",
    "environment. Based on the information the authors provided, I have derived some\n",
    "requirements that outline metrics I will be collecting.\n",
    "\n",
    "#### Requirements\n",
    "\n",
    "| Requirement | Description                                                                                    | Description                                           | Verification Method |\n",
    "|-------------|------------------------------------------------------------------------------------------------|-------------------------------------------------------|---------------------|\n",
    "| HIRISE-001  | A neural network model shall be trained on the HiRISE v3.2 dataset.                            | The goal of the project is to classify HiRISE images. | Test Set Evaluation |\n",
    "| HIRISE-002  | A neural network model shall achieve a minimum of 80% accuracy on the test dataset.            | The model needs to be nearly as good as AlexNet.      | Test Set Evaluation |\n",
    "| HIRISE-003  | A neural network model shall execute on the NVIDIA Jetson Nano 2GB.                            | The flight software board is the NVIDIA Jetson Nano.  | Inspection          |\n",
    "| HIRISE-004  | A neural network model inference time shall not exceed 40.0 ms                                 | The existing benchmark for HiRISENet is 1,069 ms.     | Profiling           |\n",
    "| HIRISE-005  | A neural network model size shall not exceed 233 MB.                                           | AlexNet in PyTorch 2.5 is ~233 MB in size.            | Profiling           |\n",
    "| HIRISE-006  | A neural network's peak RAM utilization on the CPU shall not exceed 60.0 MB                    | This is the allocated RAM for the neural network      | Profiling           |\n",
    "| HIRISE-007  | A neural network's floating-point operations shall not exceed 7.0e9                            | This is the allocated RAM for the neural network      | Profiling           |\n",
    "\n",
    "My intent is to bring my perspective as a flight software engineer to machine\n",
    "learning. I will be providing commentary throughout this Jupyter Notebook on\n",
    "my thoughts in the matter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Lets get some basic project infrastructure set up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"data\")\n",
    "sys.path.append(\"utils\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.gpu_management import GPUManager\n",
    "\n",
    "from data.dataset import HiRISE\n",
    "from data.split_type import SplitType\n",
    "import torchvision\n",
    "from torchvision.transforms import v2\n",
    "from pathlib import Path\n",
    "from model.adapt import get_modified_efficientnet_b0\n",
    "from model.insights import (\n",
    "    plot_model_sizes,\n",
    "    plot_model_flops,\n",
    "    plot_cpu_execution_time,\n",
    "    plot_max_mem_usage,\n",
    ")\n",
    "from model.training import train_model\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = GPUManager.enable_gpu_if_available()\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    GPUManager.cleanup_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis\n",
    "\n",
    "The first thing we should do is gain a deep understanding of our dataset. As\n",
    "mentioned in the introduction, the model we train is a direct reflection of our\n",
    "data. That is, the model _is_ the data.\n",
    "\n",
    "The HiRISE v3.2 [[2]](#2) dataset has the following characteristics:\n",
    "\n",
    "* **Number of Classes:** The dataset comprises of 8 different classes, each representing different Martian terrain features: bright dune, crater, dark dune, impact ejecta, other, slope streak, spider, swiss cheese.\n",
    "\n",
    "* **Images:** The dataset contains 64,947 227x227 images. The images have been pre-processed and a subset of the original images were augmented with the following transformations: 90° clockwise rotation, 180° clockwise rotation, 270° clockwise rotation, horizontal flip, vertical flip, random brightness adjustment.\n",
    "\n",
    "* **File Format:** The images are stored in JPG format.\n",
    "\n",
    "* **Directory Structure:** The data has been split by the authors into a training, validation, and test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can feed our dataset into a model, we need to transform it into a\n",
    "format that the model can understand. For this, we use the `transforms` module\n",
    "from `torchvision`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size: tuple = (227, 227)\n",
    "\n",
    "data_transforms = {\n",
    "    \"train\": v2.Compose(\n",
    "        [\n",
    "            v2.Resize(image_size),\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.RandomRotation(degrees=10),\n",
    "            v2.RandomHorizontalFlip(),\n",
    "            v2.RandomVerticalFlip(),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": torchvision.transforms.v2.Compose(\n",
    "        [v2.Resize(image_size), v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]\n",
    "    ),\n",
    "    \"test\": torchvision.transforms.v2.Compose(\n",
    "        [v2.Resize(image_size), v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the transforms I use are pretty standard for image data.\n",
    "We first resize each image to 227x227. The images should already be this size\n",
    "but you can never be too careful. The `v2.ToImage()` and `v2.ToDtype(...)`\n",
    "are the new PyTorch v2 recommended way of transforming an image to a tensor.\n",
    "The old `ToTensor()` is deprecates as of this writing.\n",
    "\n",
    "I also used some fairly standard geometric transformations like rotating the\n",
    "image or flipping the image. Geometric transformations are highly effective\n",
    "at helping a model generalize and train well. Augmentations also have a\n",
    "regularizing effect which helps prevent a model from overfitting, or memorizing,\n",
    "the data instead of actually learning. Plus, augmentations are a way of getting\n",
    "more data for \"free\".\n",
    "\n",
    "From what I've read, higher resolution images provides more pixels or\n",
    "features for a neural network to chew and nitpick on. Thus, increasing the\n",
    "learning capacity of the model. However, this also increases the storage size of the\n",
    "images themselves and the computational costs of the model. On resource-constrained\n",
    "spacecraft where everything has a constraint and a limited budget, that presents\n",
    "a challenge. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder: Path = Path(\"/tmp/.hirise\")\n",
    "\n",
    "train_dataset = HiRISE(\n",
    "    root_dir=data_folder,\n",
    "    split_type=SplitType.TRAIN,\n",
    "    transform=data_transforms[\"train\"],\n",
    "    target_transform=lambda data: torch.tensor(data, dtype=torch.long),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "val_dataset = HiRISE(\n",
    "    root_dir=data_folder,\n",
    "    split_type=SplitType.VAL,\n",
    "    transform=data_transforms[\"val\"],\n",
    "    target_transform=lambda data: torch.tensor(data, dtype=torch.long),\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "test_dataset = HiRISE(\n",
    "    root_dir=data_folder,\n",
    "    split_type=SplitType.TEST,\n",
    "    transform=data_transforms[\"test\"],\n",
    "    target_transform=lambda data: torch.tensor(data, dtype=torch.long),\n",
    "    download=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our datasets, lets see what these images actually look like.\n",
    "Lets plot one of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_image_per_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the images we show, it's clear that some of these terrains are very\n",
    "similar to each other. Two particular classes that stand out to me are the\n",
    "crater and impact ejecta. They both look like craters with the distinguishing\n",
    "feature being the brighter material surrounding the impact crater. \n",
    "\n",
    "It also seems like a crater in this dataset is an impact zone that is larger\n",
    "than an impact ejecta image. So then, what if the impact ejecta has been covered\n",
    "or eroded in the image? I wonder if the model will have some difficulties with\n",
    "that.\n",
    "\n",
    "As mentioned by the authors of the dataset, the \"other\" class is a catch-all\n",
    "class to capture anything that doesn't quite fit into the other classes. They\n",
    "also mention that this \"other\" class makes up the overwhelming majority of the\n",
    "data.\n",
    "\n",
    "Lets take a look at that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution plot we can see that the \"Other\" landmarks significantly\n",
    "dominate the class distribution. This clear imbalance of data will need to be\n",
    "accounted for in our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting Our Models\n",
    "\n",
    "As a spacecraft engineer, I prefer ol' reliable over novelty. Therefore, in this\n",
    "project I have opted for convolutional neural networks since they are a more\n",
    "mature and well understood architecture than something like a vision transformer.\n",
    "Additionally, I want a pre-trained model that will facilitate doing things like\n",
    "transfer learning which is useful in space since we have very small or\n",
    "non-existent datasets.\n",
    "\n",
    "I did some initial literature review by comparing AlexNet, ResNet18 [[6]](#6),\n",
    "EfficientNet [[7]](#7), and ConvNeXt [[8]](#8) and found that EfficientNet was\n",
    "a modern and small CNN architecture that met my needs.\n",
    "\n",
    "One last thing I identified when selecting some of these architectures was that\n",
    "they all expect three channel input images (RGB) but our dataset consists of\n",
    "single-channel greyscale images. Thus, I had to modify the input layer of each\n",
    "model to account for this discrepancy. Lastly, I modified the final layer of\n",
    "each model which does the actual class prediction from IMAGENET's 1,000 classes\n",
    "to our humble 8 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EfficientNet\n",
    "\n",
    "To get more performance out of a neural network, machine learning practitioners\n",
    "would typically scale up the network across a dimension. They'd either add\n",
    "more layers making the model deeper. Or they'd increase the resolution of the\n",
    "model. Most of these efforts were at best trial-and-error and at worst random.\n",
    "\n",
    "![Model Scaling with EfficientNet](../assets/images/model_scaling_efficientnet.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers at Google set out to create a methodical approach to scaling up\n",
    "neural networks. They wanted to consider scaling across all dimensions instead\n",
    "of one or a subset. Using\n",
    "[neural architecture search](https://en.wikipedia.org/wiki/Neural_architecture_search),\n",
    "the authors generated a family of models they named EfficientNet. The generated\n",
    "models did some neat things like depth-wise separable convolutions which are\n",
    "more efficient than classic convolutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models: dict[str, torch.nn.Module] = {}\n",
    "\n",
    "models[\"efficientnet\"] = get_modified_efficientnet_b0()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterizing Model Performance\n",
    "\n",
    "With our model architecture selected and modified for HiRISE, we are now ready\n",
    "to do some profiling to identify which models meet our project requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Sizes\n",
    "\n",
    "Per requirement **HIRISE-006**, the model size should not exceed 233.0 megabytes.\n",
    "\n",
    "Lets take a look at our selected models and eleminiate any violating models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_sizes(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the models we have selected do not exceed our HIRISE-008\n",
    "requirement. This is great! The AlexNet model stands out as being the largest\n",
    "with ~233 MB in size. An interesting thing is that modern model archirectures\n",
    "like ResNet are achieve better performance than AlexNet despire being\n",
    "significantly smaller. This could be due to novel techniques and approaches\n",
    "to architecting the newer model families."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FLOPS\n",
    "\n",
    "Next, lets calculate the number of floating-point operations (FLOPS) that our\n",
    "model executes. FLOPS are an important metric to capture as they provide some\n",
    "insights into the computational and energy requirements of the model.\n",
    "Additionally for spacecraft flight software, a general rule of thumb is that the\n",
    "less floating-point operations you do the better. That's because floating-point\n",
    "math is computationally expensive and consumes a lot of energy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model_flops(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference Latency\n",
    "\n",
    "Per our requirement **HIRISE-004**, the inference latency of a model should not\n",
    "exceed 40.0 milliseconds for a single input image. Lets now profile each of our\n",
    "models. We sometimes want our application or code to execute within tight\n",
    "timing constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cpu_execution_time(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Peak Memory Usage\n",
    "\n",
    "The next requirement we wish to account for is **HIRISE-006**. Per this\n",
    "requirement, the model we select must not exceed a peak memory usage of 60.0\n",
    "megabytes. Lets take a look at the performance of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_max_mem_usage(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that none of our models violate this requirement. Therefore, they\n",
    "are viable candidates thus far. The next step is to train a baseline to see if\n",
    "any of our models can meet requirement **HIRISE-002** of a minimum of 80%\n",
    "accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Establishing a Baseline\n",
    "\n",
    "With our models downloaded, modified and prepared, we are ready to jump into\n",
    "training and establishing a baseline. Our objective in this first round of\n",
    "training is to identify the best performing models so that we can downselect\n",
    "from our set of models. Thereafter, we shall improve the model performance by\n",
    "introducing data augmentations and fiddling with the hyperparameters.\n",
    "\n",
    "First, we'll setup some hyperparameters\n",
    "for this round of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE: float = 1e-3\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also need to create a couple of `DataLoader` objects to easily iterate\n",
    "over our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {\n",
    "    name: torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=8, pin_memory=True\n",
    "    )\n",
    "    for name, dataset in zip(\n",
    "        [\"train\", \"val\", \"test\"], [train_dataset, val_dataset, test_dataset]\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the loss function we will use `CrossEntropyLoss`. This is a fairly standard\n",
    "loss function and is commonly used in machine learning. Similarly, the `Adam`\n",
    "and `AdamW` optimizers are fairly standard and a good go-to default optimizer\n",
    "for training deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer: torch.optim.Optimizer = torch.optim.AdamW(\n",
    "    params=models[\"efficientnet\"].parameters(), lr=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPUManager.cleanup_gpu_cache()\n",
    "\n",
    "efficientnet_ft, efficientnet_history = train_model(\n",
    "    models[\"efficientnet\"],\n",
    "    dataloaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    None,\n",
    "    device,\n",
    "    num_epochs=EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\">[1]</a> \n",
    "Wikipedia contributors. (2024, November 19). HiRISE. Wikipedia. https://en.wikipedia.org/wiki/HiRISE\n",
    "\n",
    "<a id=\"2\">[2]</a> \n",
    "Gary Doran, Emily Dunkel, Steven Lu, & Kiri Wagstaff. (2020). Mars orbital image (HiRISE) labeled data set version 3.2 (3.2.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.4002935\n",
    "\n",
    "<a id=\"3\">[3]</a>\n",
    "Wagstaff, K., Lu, Y., Stanboli, A., Grimes, K., Gowda, T., & Padams, J. (2018). Deep Mars: CNN Classification of Mars Imagery for the PDS Imaging Atlas. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1). https://doi.org/10.1609/aaai.v32i1.11404\n",
    "\n",
    "<a id=\"4\">[4]</a>\n",
    "Wagstaff, Kiri, et al. Mars Image Content Classification: Three Years of NASA Deployment and Recent Advances. arXiv:2102.05011, arXiv, 9 Feb. 2021. arXiv.org, https://doi.org/10.48550/arXiv.2102.05011.\n",
    "\n",
    "<a id=\"5\">[5]</a>\n",
    "Dunkel, Emily R., et al. “Benchmarking Deep Learning Models on Myriad and Snapdragon Processors for Space Applications.” Journal of Aerospace Information Systems, vol. 20, no. 10, Oct. 2023, pp. 660–74. DOI.org (Crossref), https://doi.org/10.2514/1.I011216.\n",
    "\n",
    "<a id=\"6\">[6]</a>\n",
    "He, Kaiming, et al. Deep Residual Learning for Image Recognition. arXiv:1512.03385, arXiv, 10 Dec. 2015. arXiv.org, https://doi.org/10.48550/arXiv.1512.03385.\n",
    "\n",
    "<a id=\"7\">[7]</a>\n",
    "Tan, Mingxing, and Quoc V. Le. EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks. arXiv:1905.11946, arXiv, 11 Sept. 2020. arXiv.org, https://doi.org/10.48550/arXiv.1905.11946.\n",
    "\n",
    "<a id=\"8\">[8]</a>\n",
    "Liu, Zhuang, et al. A ConvNet for the 2020s. arXiv:2201.03545, arXiv, 2 Mar. 2022. arXiv.org, https://doi.org/10.48550/arXiv.2201.03545.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hirisenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
