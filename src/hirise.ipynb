{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HiRISENet-Tiny\n",
    "\n",
    "A tiny neural network classifier for Mars HiRISE images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Mars HiRISE (High Resolution Imaging Science Experiment) [[1]](#1) is a camera on board the Mars Reconnaissance\n",
    "Orbiter which has been orbiting and studying Mars since 2006. A product of this payload's years of service has been the\n",
    "curation of the Mars orbital image (HiRISE) labeled data set [[2]](#2) by NASA. This dataset provides a curated set of\n",
    "labelled images of the Martian terrain from an orbital perspective. **Figure 1** shows one of the first images taken\n",
    "with the HiRISE camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--- Public Domain, https://commons.wikimedia.org/w/index.php?curid=656514 >\n",
    "--->\n",
    "![First HiRISE Image](../assets/images/mro_first_image.jpg \"Figure 1. The first orbital image captured by HiRISE\")\n",
    "\n",
    "**Figure 1. Crop of one of the first images of Mars from the HiRISE camera.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2018, Wagstaff et. al. [[3]](#3) set out to train a deep learning model to enable scientists & researchers to conduct\n",
    "advanced queries of the HiRISE data in NASA's planetary imagery database. With the first edition of the dataset, the\n",
    "authors fine-tuned the AlexNet convolutional neural network on the data. This initial dataset contained 3,820 \n",
    "greyscale images and consisted of the labels crater, dark dune, bright dune, dark slope streak, other and edge. With\n",
    "this dataset, the model achieved 99.1%, 88.1%, and 90.6% accuracy across their training, validation, and test sets\n",
    "respectively.\n",
    "\n",
    "Following this effort, Wagstaff et. al. published a follow up paper [[4]](#4) which expanded the initial dataset to\n",
    "a version 3.2. This expanded dataset consists of a total of 64,947 landmark images. These images have been preprocessed\n",
    "and cropped to a 227x227 size similar to the first edition. In v3.2, a subset of these images, 9,022, were augmented \n",
    "using a variety of image augmentation techniques applied individually to the subset of images. This artificially\n",
    "expanded the available data. The authors also introduced the classes impact ejecta, spiders, and swiss cheese while\n",
    "removing edge.\n",
    "\n",
    "![HiRISE v3.2 Class Imagse](../assets/images/hirise_v3_classes.png)\n",
    "\n",
    "The authors also fine-tuned the AlexNet model on the new dataset. For this iteration, the authors analyzed the model's\n",
    "confidence and utilized calibration techniques to make the model more reliable. With this approach and improved dataset,\n",
    "the authors managed to improve the model's classification accuracy to\n",
    "{\"train\": 99.6%, \"val\": 88.6%, \"test\": 92.8%}.\n",
    "\n",
    "![Dataset Class Distribution](../assets/images/hirise_dataset_class_distribution.png)\n",
    "\n",
    "An important thing to note is that the class distribution is pretty unbalanced. Images of \"Other\" significantly\n",
    "dominate the dataset while \"Impact Ejecta\" constitutes a small portion of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About this Project\n",
    "\n",
    "In this project I challenged myself to develop a pipeline for training and inference of a neural network to run on the\n",
    "NVIDIA Jetson Nano 2GB that classifies HiRISE images.\n",
    "\n",
    "Given the resource constraints of space-based computing platforms, I set out to train a neural network that would\n",
    "hypothetically be deployed on-orbit to classify images. My goal is to train a model that is more resource efficient\n",
    "than the author's AlexNet and be almost (ðŸ¤ž) as good or, hopefully, better.\n",
    "\n",
    "Most importantly, this project is meant to be fun filled with learning opportunities on training a model, making sure\n",
    "the model is reliable, and exploring approaches on how to make a model more efficient. I am, after all, a spacecraft\n",
    "flight software engineer.\n",
    "\n",
    "For this project I want to follow Andrej Karpathy's\n",
    "\"[A Recipe for Training Neural Networks](https://karpathy.github.io/2019/04/25/recipe/)\" and follow some best practices\n",
    "described by a leader in AI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Lets get some basic project infrastructure set up first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils.gpu_management import GPUManager\n",
    "\n",
    "from data.dataset import HiRISE\n",
    "from data.split_type import SplitType\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "\n",
    "device = GPUManager.enable_gpu_if_available()\n",
    "\n",
    "if device.type == \"cuda\":\n",
    "    GPUManager.cleanup_gpu_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Become one with the data\n",
    "\n",
    "Per Karpathy, the most important rule is that we become intimately familiar\n",
    "with the data we are working with. That is because our trained neural network\n",
    "is a direct reflection of the data it was trained on. That is, the model _is_\n",
    "the data!\n",
    "\n",
    "Fortunately, for this dataset, the authors have done a lot of heavy lifting in\n",
    "preparing and curating a high quality dataset.\n",
    "\n",
    "What would be of great benefit to us is to visualize and understand the\n",
    "different types of features we are training the model to classify.\n",
    "\n",
    "Lets take a look."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets create dataset objects to be able to easily load and view our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets start with some basic ones. We don't want to augment just yet.\n",
    "img_transforms: v2.Compose = v2.Compose(\n",
    "    [v2.Resize((227, 227)), v2.ToImage(), v2.ToDtype(torch.float32, scale=True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HiRISE(\n",
    "    root_dir=\"/tmp/.dataset\",\n",
    "    split_type=SplitType.TRAIN,\n",
    "    transform=img_transforms,\n",
    "    download=True,\n",
    ")\n",
    "\n",
    "val_dataset = HiRISE(\n",
    "    root_dir=\"/tmp/.dataset\",\n",
    "    split_type=SplitType.VAL,\n",
    "    transform=img_transforms,\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "test_dataset = HiRISE(\n",
    "    root_dir=\"/tmp/.dataset\",\n",
    "    split_type=SplitType.TEST,\n",
    "    transform=img_transforms,\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our datasets, lets see what these images actually look like.\n",
    "Lets plot one of each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_image_per_class()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the images we show, it's clear that some of these terrains are very\n",
    "similar to each other. Two particular classes that stand out to me are the\n",
    "crater and impact ejecta. They both look like craters with the distinguishing\n",
    "feature being the brighter material surrounding the impact crater. \n",
    "\n",
    "It also seems like a crater in this dataset is an impact zone that is larger\n",
    "than an impact ejecta image. So then, what if the impact ejecta has been covered\n",
    "or eroded in the image? I wonder if the model will have some difficulties with\n",
    "that.\n",
    "\n",
    "As mentioned by the authors of the dataset, the \"other\" class is a catch-all\n",
    "class to capture anything that doesn't quite fit into the other classes. They\n",
    "also mention that this \"other\" class makes up the overwhelming majority of the\n",
    "data.\n",
    "\n",
    "Lets take a look at that now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.show_class_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the distribution plot we can see that the \"Other\" landmarks significantly\n",
    "dominate the class distribution. This clear imbalance of data will need to be\n",
    "accounted for in our model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Set up the end-to-end training/evaluation skeleton + get dumb baselines\n",
    "\n",
    "Next up, we'll want to setup our training & evaluation pipeline. We'll also\n",
    "want to get some stupid simple and dumb baseline by using a stupid and simple\n",
    "model.\n",
    "\n",
    "For this phase we want to simply establish our baselines. To accomplish that,\n",
    "we need to follow a good ol' software engineering principle: KISS.\n",
    "\n",
    "That is, keep it simple stupid!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for each dataset\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=32, shuffle=True, num_workers=8, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE: float = 1e-4\n",
    "BATCH_SIZE: int = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "model = torchvision.models.convnext_tiny(\n",
    "    weights=torchvision.models.ConvNeXt_Tiny_Weights.IMAGENET1K_V1\n",
    ")\n",
    "\n",
    "model.features[0][0] = torch.nn.Conv2d(\n",
    "    1, 96, kernel_size=(4, 4), stride=(4, 4), device=device\n",
    ")\n",
    "\n",
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import model_insights\n",
    "\n",
    "model_insights.calc_model_size(model, show=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"1\">[1]</a> \n",
    "Wikipedia contributors. (2024, November 19). HiRISE. Wikipedia. https://en.wikipedia.org/wiki/HiRISE\n",
    "\n",
    "<a id=\"2\">[2]</a> \n",
    "Gary Doran, Emily Dunkel, Steven Lu, & Kiri Wagstaff. (2020). Mars orbital image (HiRISE) labeled data set version 3.2 (3.2.0) [Data set]. Zenodo. https://doi.org/10.5281/zenodo.4002935\n",
    "\n",
    "<a id=\"3\">[3]</a>\n",
    "Wagstaff, K., Lu, Y., Stanboli, A., Grimes, K., Gowda, T., & Padams, J. (2018). Deep Mars: CNN Classification of Mars Imagery for the PDS Imaging Atlas. Proceedings of the AAAI Conference on Artificial Intelligence, 32(1). https://doi.org/10.1609/aaai.v32i1.11404\n",
    "\n",
    "<a id=\"4\">[4]</a>\n",
    "Wagstaff, Kiri, et al. Mars Image Content Classification: Three Years of NASA Deployment and Recent Advances. arXiv:2102.05011, arXiv, 9 Feb. 2021. arXiv.org, https://doi.org/10.48550/arXiv.2102.05011."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hirisenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
